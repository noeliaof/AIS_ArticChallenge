{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9662657d-0ee6-408d-94fe-da71539dcfd5",
   "metadata": {},
   "source": [
    "# AutoICE - test model and prepare upload package\n",
    "This notebook tests the 'best_model', created in the quickstart notebook, with the tests scenes exempt of reference data. The model outputs are stored per scene and chart in an xarray Dataset in individual Dataarrays. The xarray Dataset is saved and compressed in an .nc file ready to be uploaded to the AI4EO.eu platform. Finally, the scene chart inference is shown.\n",
    "\n",
    "The first cell imports necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cabf3fe-44c3-42f0-b061-5a70b64379be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Built-in modules -- #\n",
    "import os\n",
    "\n",
    "# -- Third-part modules -- #\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import xarray as xr\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# --Proprietary modules -- #\n",
    "from functions import chart_cbar, r2_metric, f1_metric, compute_metrics\n",
    "from loaders import AI4ArcticChallengeTestDataset\n",
    "from unet import UNet\n",
    "from utils import CHARTS, SIC_LOOKUP, SOD_LOOKUP, FLOE_LOOKUP, SCENE_VARIABLES, colour_str\n",
    "%store -r train_options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b270975-ef64-45c0-bfa0-5f3d48504ab5",
   "metadata": {},
   "source": [
    "### Setup of the GPU resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a3e19a1-76d0-4047-b4a4-8b5f8af19bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32mGPU available!\u001b[0m\n",
      "Total number of available devices:  \u001b[0;33m2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Get GPU resources.\n",
    "if torch.cuda.is_available():\n",
    "    print(colour_str('GPU available!', 'green'))\n",
    "    print('Total number of available devices: ', colour_str(torch.cuda.device_count(), 'orange'))\n",
    "    device = torch.device(f\"cuda:{train_options['gpu_id']}\")\n",
    "\n",
    "else:\n",
    "    print(colour_str('GPU not available.', 'red'))\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8d365e-0a78-43f2-9182-776148c80d31",
   "metadata": {},
   "source": [
    "### Load the model and stored parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e164255-8528-46b3-9ce6-6bc27c0effae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model.\n",
      "Model successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "print('Loading model.')\n",
    "# Setup U-Net model, adam optimizer, loss function and dataloader.\n",
    "net = UNet(options=train_options).to(device)\n",
    "net.load_state_dict(torch.load('best_model')['model_state_dict'])\n",
    "print('Model successfully loaded.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d16af23-a901-4ca6-8d75-7a54d66a1eaa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prepare the scene list, dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28f92af3-32ab-4752-832a-29b5972ac375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup ready\n"
     ]
    }
   ],
   "source": [
    "with open(train_options['path_to_env'] + 'datalists/testset.json') as file:\n",
    "    train_options['test_list'] = json.loads(file.read())\n",
    "train_options['test_list'] = [file[17:32] + '_' + file[77:80] + '_prep.nc' for file in train_options['test_list']]\n",
    "train_options['path_to_processed_data'] = '/storage/homefs/no21h426/AI4/data/test/'  # Update path - The test data is stored in a separate folder inside the training data.\n",
    "upload_package = xr.Dataset()  # To store model outputs.\n",
    "dataset = AI4ArcticChallengeTestDataset(options=train_options, files=train_options['test_list'], test=True)\n",
    "asid_loader = torch.utils.data.DataLoader(dataset, batch_size=None, num_workers=train_options['num_workers_val'], shuffle=False)\n",
    "print('Setup ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20730e27-e0cc-4c1a-87a8-f2145d32f5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d83583c3d6ac412fa305c62b5db38dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.34 GiB (GPU 0; 10.76 GiB total capacity; 7.12 GiB already allocated; 1.98 GiB free; 7.80 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# with torch.no_grad(), torch.cuda.amp.autocast():\u001b[39;00m\n\u001b[1;32m     10\u001b[0m  \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 11\u001b[0m      output \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minf_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m  \u001b[38;5;28;01mfor\u001b[39;00m chart \u001b[38;5;129;01min\u001b[39;00m train_options[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcharts\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     14\u001b[0m      output[chart] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(output[chart], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/.conda/envs/pyAI/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/AI4ArcticSeaIceChallenge/unet.py:57\u001b[0m, in \u001b[0;36mUNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m up_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(x_contract)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m expand_block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpand_blocks:\n\u001b[0;32m---> 57\u001b[0m     x_expand \u001b[38;5;241m=\u001b[39m \u001b[43mexpand_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_expand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_contract\u001b[49m\u001b[43m[\u001b[49m\u001b[43mup_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     up_idx \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m            \n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSIC\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msic_feature_map(x_expand),\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSOD\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msod_feature_map(x_expand),\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFLOE\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfloe_feature_map(x_expand)}\n",
      "File \u001b[0;32m~/.conda/envs/pyAI/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/AI4ArcticSeaIceChallenge/unet.py:145\u001b[0m, in \u001b[0;36mExpandingBlock.forward\u001b[0;34m(self, x, x_skip)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# Insure that x and skip H and W dimensions match.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m x \u001b[38;5;241m=\u001b[39m expand_padding(x, x_skip, padding_style\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_style)\n\u001b[0;32m--> 145\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_skip\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdouble_conv(x)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.34 GiB (GPU 0; 10.76 GiB total capacity; 7.12 GiB already allocated; 1.98 GiB free; 7.80 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "print('Testing.')\n",
    "os.makedirs('inference', exist_ok=True)\n",
    "net.eval()\n",
    "for inf_x, _, masks, scene_name in tqdm(iterable=asid_loader, total=len(train_options['test_list']), colour='green', position=0):\n",
    "    scene_name = scene_name[:19]  # Removes the _prep.nc from the name.\n",
    "    #torch.cuda.empty_cache()\n",
    "    inf_x = inf_x.to(device, non_blocking=True)\n",
    "    torch.cuda.empty_cache()\n",
    "   # with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "    with torch.no_grad():\n",
    "        output = net(inf_x)\n",
    "\n",
    "    for chart in train_options['charts']:\n",
    "        output[chart] = torch.argmax(output[chart], dim=1).squeeze().cpu().numpy()\n",
    "        upload_package[f\"{scene_name}_{chart}\"] = xr.DataArray(name=f\"{scene_name}_{chart}\", data=output[chart].astype('uint8'),\n",
    "                                                               dims=(f\"{scene_name}_{chart}_dim0\", f\"{scene_name}_{chart}_dim1\"))\n",
    "\n",
    "    # - Show the scene inference.\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(10, 10))\n",
    "    for idx, chart in enumerate(train_options['charts']):\n",
    "        ax = axs[idx]\n",
    "        output[chart] = output[chart].astype(float)\n",
    "        output[chart][masks] = np.nan\n",
    "        ax.imshow(output[chart], vmin=0, vmax=train_options['n_classes'][chart] - 2, cmap='jet', interpolation='nearest')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        chart_cbar(ax=ax, n_classes=train_options['n_classes'][chart], chart=chart, cmap='jet')\n",
    "    \n",
    "    plt.suptitle(f\"Scene: {scene_name}\", y=0.65)\n",
    "    plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0.5, hspace=-0)\n",
    "    fig.savefig(f\"inference/{scene_name}.png\", format='png', dpi=128, bbox_inches=\"tight\")\n",
    "    plt.close('all')\n",
    "\n",
    "\n",
    "# - Save upload_package with zlib compression.\n",
    "print('Saving upload_package. Compressing data with zlib.')\n",
    "compression = dict(zlib=True, complevel=1)\n",
    "encoding = {var: compression for var in upload_package.data_vars}\n",
    "upload_package.to_netcdf('upload_package.nc', mode='w', format='netcdf4', engine='netcdf4', encoding=encoding)\n",
    "print('Testing completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4226ab84-2860-4bbe-9f3b-876bd3a036d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyAI",
   "language": "python",
   "name": "pyai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
